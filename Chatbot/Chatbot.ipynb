{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OPEN DOCUMENT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openDocument(path):\n",
    "    return open(path, 'r', errors = 'ignore', encoding = '#utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = openDocument('DataText/PierreInfoText.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TOKENIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(doc):\n",
    "    raw_doc = doc.read()\n",
    "    raw_doc = raw_doc.lower()\n",
    "    # nltk.download('punkt')\n",
    "    # nltk.download('wordnet')\n",
    "    # nltk.download('omw-1.4')\n",
    "    # nltk.download('stopwords')\n",
    "    return nltk.sent_tokenize(raw_doc), nltk.word_tokenize(raw_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens, word_tokens = tokenization(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['le tailleur de pierre conçoit sur mesure des éléments architecturaux ou décoratifs en pierre de taille\\n  les métiers de la pierre regroupent plusieurs activités artisanales.',\n",
       " \"elles commencent avec l'extraction de la pierre et le métier de carrier.\",\n",
       " 'celui de tailleur de pierre et de marbrier de décoration et funéraire, incluant le métier de graveur.',\n",
       " \"sans oublier l'option artistique que représente la sculpture ornementale.\",\n",
       " \"des gestes traditionnels à l'utilisation de machines à la pointe du progrès, l'artisan tailleur de pierre cherche l'harmonie entre la tradition et les techniques modernes qui s'imposent aujourd'hui.\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['le', 'tailleur']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEXT PROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remPunct():\n",
    "    return dict((ord(punct), None) for punct in string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_punct_dict = remPunct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LemTokens(tokens):\n",
    "    lemmer = nltk.stem.WordNetLemmatizer()\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REPONSE GENERATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    robo1_response = ''\n",
    "\n",
    "    final_stopwords_list = stopwords.words('french')\n",
    "    TfidfVec = TfidfVectorizer(\n",
    "    stop_words=final_stopwords_list,\n",
    "    tokenizer=LemNormalize,\n",
    "    )\n",
    "    \n",
    "    #TfidfVec = TfidfVectorizer(tokenizer = LemNormalize, stop_words = 'english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx = vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robo1_response =  robo1_response + \"Désolé, je ne comprends pas! Pourrais tu reformuler la phrase?\"\n",
    "        return robo1_response\n",
    "    else:\n",
    "        robo1_response = robo1_response + sent_tokens[idx] + \"\\nBOT: Si je ne réponds pas correctement à votre question, essayez de la reformuler. Si vous avez une autre question n'hésitez pas à me la poser!\"\n",
    "        return robo1_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**START AND END PROTOCOL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def protocol(wordTokens):\n",
    "    flag = True\n",
    "    intro = input('BOT: Bonjour, je suis votre assistant aujourd\\'hui. Comment puis-je vous aider ?\\nSi vous avez un message d\\'erreur, tapez \"erreur\", si vous voulez en savoir plus sur le monde de la pierre, tapez \"info\".\\nTapez \"sortie\" à tout moment quand vouz souhaitez quitter la conversation\\n')\n",
    "\n",
    "    while intro.lower() not in ['info', 'erreur', 'sortie']:\n",
    "        intro = str(input('BOT: Désolé, il semble y avoir un problème. Veuillez taper soit le mot \\\"info\\\" soit le mot \\\"erreur\\\"\\n'))\n",
    "\n",
    "    if intro.lower() == 'info':\n",
    "        print('BOT: Je vous écoute! Veuillez me poser une question sur le monde du taille de la pierre.\\nLe moins de mots vous inserez, le plus facile sera pour moi de vous donner une réponse pertinente :)')\n",
    "        while(flag == True):\n",
    "            user_response = input()\n",
    "            user_response = user_response.lower()\n",
    "            if(user_response != 'sortie'):\n",
    "                if(user_response == 'merci' or user_response == 'merci beaucoup'):\n",
    "                    flag = False\n",
    "                    print('BOT: Aucun problème!')\n",
    "                else:\n",
    "                    sent_tokens.append(user_response)\n",
    "                    wordTokens = wordTokens + nltk.word_tokenize(user_response)\n",
    "                    final_words = list(set(wordTokens))\n",
    "                    print(\"BOT: \", end = \"\")\n",
    "                    print(response(user_response))\n",
    "                    sent_tokens.remove(user_response)\n",
    "            else:\n",
    "                flag = False\n",
    "                print(\"BOT: Au revoir! A bientôt\")\n",
    "                \n",
    "    elif intro.lower() == 'erreur':\n",
    "        print ('BOT: partie erreur')\n",
    "\n",
    "    else:\n",
    "        flag = False\n",
    "        print(\"BOT: Au revoir! A bientôt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOT: Je vous écoute! Veuillez me poser une question sur le monde du taille de la pierre.\n",
      "Le moins de mots vous inserez, le plus facile sera pour moi de vous donner une réponse pertinente :)\n",
      "BOT: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxba\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['a', 'avon', 'e', 'fuss', 'no', 'pa', 'serum', 'somme'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en taille de pierre, le système de foration doit être adapté au travail à effectuer et à la nature de la pierre.\n",
      "BOT: Si je ne réponds pas correctement à votre question, essayez de la reformuler. Si vous avez une autre question n'hésitez pas à me la poser!\n",
      "BOT: Désolé, je ne comprends pas! Pourrais tu reformuler la phrase?\n",
      "BOT: Aucun problème!\n"
     ]
    }
   ],
   "source": [
    "protocol(word_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9475284635d26067614a2f5c1768a08b1468dbbebaf0733e7f66e6cab11f2ea7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
